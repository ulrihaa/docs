# Фундаментальные модели в {{ ml-platform-name }}

{{ ml-platform-full-name }} предоставляет возможность работать с фундаментальными моделями, чтобы вы могли использовать их для решения своих задач и при необходимости дообучать на своих данных. Дообучение производится по методу Fine-tuning, результаты дообучения хранятся в {{ ml-platform-name }}.

{% note info %}

Дообучение фундаментальных моделей находится на стадии [Preview](../../../overview/concepts/launch-stages.md).

{% endnote %}

В разделе **Фундаментальные модели** доступна модель {{ yagpt-name }}. Вы можете использовать ее в {{ ml-platform-name }} как есть или дообучить на своих данных, чтобы ответы модели точнее отражали специфику ваших задач. Результат дообучения модели будет доступен из проектов {{ ml-platform-name }} и через [API сервиса {{ yagpt-name }}](../../../yandexgpt/api-ref/authentication.md). 

## Данные для дообучения {{ yagpt-name }} {#yagpt-tuning}

Чтобы дообучить модель {{ yagpt-name }} по методу Fine-tuning, вам нужно подготовить файл в формате JSON, содержащий примеры как минимум 10 запросов и эталонных ответов. Сохраните файл в кодировке [UTF-8](https://ru.wikipedia.org/wiki/UTF-8):

```json
[
  {
    "request": "текстовый запрос",
    "response": "ожидаемый ответ"
  },
  {
    "request": "еще один текстовый запрос",
    "response": "новый ожидаемый ответ"
  },
  …
]
```

Файл может содержать не больше 10 000 вопросов и ответов. Максимальная длина запроса — 4000 символов, максимальная длина эталонного ответа — 2000 символов. 

В интерфейсе {{ ml-platform-name }} создайте новую дообученную фундаментальную модель, введите инструкцию для модели, задайте темп обучения и загрузите данные. Дообучение займет некоторое время.